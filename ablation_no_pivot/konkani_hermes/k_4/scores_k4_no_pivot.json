{
  "bleu": 0.10350404571916846,
  "chrf": 1.6155304465369522,
  "chrf++": 1.4027740687315298,
  "num_samples": 205,
  "successful": 5,
  "failed": 200,
  "inference_time": 13.754260540008545,
  "config": {
    "model": "NousResearch/Hermes-2-Pro-Llama-3-8B",
    "source": "eng",
    "target": "gom",
    "num_examples": 4,
    "pivot": "NONE (direct translation)",
    "batch_size": 8
  }
}